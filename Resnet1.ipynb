{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaisacht/Project/blob/main/Resnet1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phNA0Ess1um1"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFdDi78818Ns"
      },
      "outputs": [],
      "source": [
        "np.random.seed(813306)\n",
        "print(np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8jfpKmu2Jaj"
      },
      "outputs": [],
      "source": [
        "def build_resnet(input_shape, n_feature_maps, nb_classes):\n",
        "    print ('build conv_x')\n",
        "    x = keras.layers.Input(shape=(input_shape))\n",
        "    conv_x = keras.layers.BatchNormalization()(x)\n",
        "    conv_x = keras.layers.Conv2D(n_feature_maps, 8, 1, padding='same')(conv_x)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "     \n",
        "    print ('build conv_y')\n",
        "    conv_y = keras.layers.Conv2D(n_feature_maps, 5, 1, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "     \n",
        "    print ('build conv_z')\n",
        "    conv_z = keras.layers.Conv2D(n_feature_maps, 3, 1, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "     \n",
        "    is_expand_channels = not (input_shape[-1] == n_feature_maps)\n",
        "    if is_expand_channels:\n",
        "        shortcut_y = keras.layers.Conv2D(n_feature_maps, 1, 1,padding='same')(x)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    else:\n",
        "        shortcut_y = keras.layers.BatchNormalization()(x)\n",
        "    print ('Merging skip connection')\n",
        "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
        "    y = keras.layers.Activation('relu')(y)\n",
        "     \n",
        "    print ('build conv_x')\n",
        "    x1 = y\n",
        "    conv_x = keras.layers.Conv2D(n_feature_maps*2, 8, 1, padding='same')(x1)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "    \n",
        "    print ('build conv_y')\n",
        "    conv_y = keras.layers.Conv2D(n_feature_maps*2, 5, 1, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "     \n",
        "    print ('build conv_z')\n",
        "    conv_z = keras.layers.Conv2D(n_feature_maps*2, 3, 1, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "     \n",
        "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
        "    if is_expand_channels:\n",
        "        shortcut_y = keras.layers.Conv2D(n_feature_maps*2, 1, 1,padding='same')(x1)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    else:\n",
        "        shortcut_y = keras.layers.BatchNormalization()(x1)\n",
        "    print ('Merging skip connection')\n",
        "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
        "    y = keras.layers.Activation('relu')(y)\n",
        "     \n",
        "    print ('build conv_x')\n",
        "    x1 = y\n",
        "    conv_x = keras.layers.Conv2D(n_feature_maps*2, 8, 1, padding='same')(x1)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "     \n",
        "    print ('build conv_y')\n",
        "    conv_y = keras.layers.Conv2D(n_feature_maps*2, 5, 1, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "     \n",
        "    print ('build conv_z')\n",
        "    conv_z = keras.layers.Conv2D(n_feature_maps*2, 3, 1, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "\n",
        "    is_expand_channels = not (input_shape[-1] == n_feature_maps*2)\n",
        "    if is_expand_channels:\n",
        "        shortcut_y = keras.layers.Conv2D(n_feature_maps*2, 1, 1,padding='same')(x1)\n",
        "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    else:\n",
        "        shortcut_y = keras.layers.BatchNormalization()(x1)\n",
        "    print ('Merging skip connection')\n",
        "    y = keras.layers.Add()([shortcut_y, conv_z])\n",
        "    y = keras.layers.Activation('relu')(y)\n",
        "     \n",
        "    full = keras.layers.GlobalAveragePooling2D()(y)\n",
        "    out = keras.layers.Dense(nb_classes, activation='softmax')(full)\n",
        "    print ('        -- model was built.')\n",
        "    return x, out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM2WkkXa850D"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INtq9TGnCd64"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"dataset_9class_3day_TEST.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rW_cZ3LPPMg8"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Abr33SuACpQx"
      },
      "outputs": [],
      "source": [
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cl1T_3KO2Noi"
      },
      "outputs": [],
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter = ',')\n",
        "    Y = data[:,0]\n",
        "    X = data[:,1:]\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxibZbQwPloy"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = readucr('dataset_9class_3day_TRAIN.txt')\n",
        "x_test, y_test = readucr('dataset_9class_3day_TEST.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVYOJkLsPr5a"
      },
      "outputs": [],
      "source": [
        "print(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPgHnJkL2Q7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "nb_epochs = 1500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfgvgPc12bhq"
      },
      "outputs": [],
      "source": [
        "flist  = ['Adiac']\n",
        "for each in flist:\n",
        "    fname = each\n",
        "    x_train, y_train = readucr('dataset_9class_3day_TRAIN.txt')\n",
        "    x_test, y_test = readucr('dataset_9class_3day_TEST.txt')\n",
        "    nb_classes = len(np.unique(y_test))\n",
        "    batch_size = min(x_train.shape[0]/10, 16)\n",
        "     \n",
        "    y_train = (y_train - y_train.min())/(y_train.max()-y_train.min())*(nb_classes-1)\n",
        "    y_test = (y_test - y_test.min())/(y_test.max()-y_test.min())*(nb_classes-1)\n",
        "     \n",
        "     \n",
        "    Y_train = keras.utils.to_categorical(y_train, nb_classes)\n",
        "    Y_test = keras.utils.to_categorical(y_test, nb_classes)\n",
        "     \n",
        "    x_train_mean = x_train.mean()\n",
        "    x_train_std = x_train.std()\n",
        "    x_train = (x_train - x_train_mean)/(x_train_std)\n",
        "      \n",
        "    x_test = (x_test - x_train_mean)/(x_train_std)\n",
        "    x_train = x_train.reshape(x_train.shape + (1,1,))\n",
        "    x_test = x_test.reshape(x_test.shape + (1,1,))\n",
        "     \n",
        "     \n",
        "    x , y = build_resnet(x_train.shape[1:], 64, nb_classes)\n",
        "    model = keras.models.Model(inputs=x, outputs=y)\n",
        "    optimizer = keras.optimizers.Adam()\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "      \n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
        "                      patience=50, min_lr=0.0001) \n",
        "    hist = model.fit(x_train, Y_train, batch_size=batch_size, epochs=nb_epochs,\n",
        "              verbose=1, validation_data=(x_test, Y_test), callbacks = [reduce_lr])\n",
        "    log = pd.DataFrame(hist.history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKp513caM4pU"
      },
      "outputs": [],
      "source": [
        "print(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rx3FYoTPDpk"
      },
      "outputs": [],
      "source": [
        "log_np = np.array(log)\n",
        "log_np\n",
        "min_index = (np.argmin(log_np, axis=0))\n",
        "print(log_np[min_index[0]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQpP6K4t7hhh"
      },
      "outputs": [],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZzFbcJ-3E4D"
      },
      "source": [
        "# Mục mới"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OEKH64Kips06IeGjhXBn2YdPWcOqa0Mi",
      "authorship_tag": "ABX9TyP9EDHRmSjYhfynMZy+Dono",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}